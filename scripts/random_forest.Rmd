---
title: "random_forest_hogar"
output: html_document
date: "2025-04-13"
---

```{r}
# --- CARGA DE PAQUETES ---
# Se utiliza 'pacman' para cargar/instalar múltiples paquetes de manera eficiente
require(pacman)

# Paquetes utilizados:
# - tidyverse: Manipulación y visualización de datos
# - caret: Machine Learning
# - glmnet: Modelos lineales regularizados
# - Metrics: Métricas de evaluación
# - skimr: Resumen rápido de datos
# - ranger: Implementación eficiente de Random Forest
# - data.table: Manipulación rápida de datos
# - xgboost: Algoritmo de boosting
p_load(
  tidyverse,
  caret,
  glmnet,
  Metrics,
  skimr,
  ranger, 
  caret,
  data.table,
  xgboost
  )
```

# Carga de datos

```{r}
# Definición de rutas:
# - raw_data_path: Directorio con datos crudos
# - predictions_path: Directorio para guardar predicciones
raw_data_path <- '../data'
predictions_path <- '../results/predictions'

# Carga de conjuntos de datos:
# - bd_train: Datos de entrenamiento (limpios)
# - bd_test: Datos de prueba (limpios)
bd_train <- read.csv(file.path(raw_data_path, 'bd_train_limpia.csv'))
bd_test <- read.csv(file.path(raw_data_path, 'bd_test_limpia.csv'))

```


# Modelo de RF 
```{r}
# Fórmula del modelo:
# Variable dependiente: Pobre
# Variables independientes: 34 predictores demográficos, económicos y laborales
model_tree1 <- Pobre ~ Cabecera + Dominio + num_room + num_bed + propiedad + 
  pago_amort + renta_h + renta_r + Nper + Depto + suma_antiguedad + 
  promedio_antiguedad + tiene_empleado_publico + tiene_patron + 
  tiene_cuenta_propia + tiene_emp_domestico + tiene_jornalero + 
  tiene_sin_remuneracion + n_posiciones_lab_distintas + aux_trans + ind_prima + 
  prima_serv + prima_nav + prima_vac + ind_viaticos + pension + ocupado + 
  ind_oficio + ind_arriendo + pet_trabajo + max_educ + hr_extr + otro_tr + 
  rem_ext + reg_cotiz + cotiz_pen + ing_otros + edad_prom + perc_fem
```

```{r}
# --- PREPARACIÓN DE DATOS DE ENTRENAMIENTO/VALIDACIÓN ---
set.seed(1004)  # Semilla para reproducibilidad

# Creación de particiones:
# - 80% para entrenamiento (bd_tr)
# - 20% para validación (bd_validation)
# Método createDataPartition de caret preserva la distribución de la variable objetivo
inTrain <- createDataPartition(
  y = bd_train$Pobre,  # Variable objetivo
  p = .80,             # Proporción para entrenamiento
  list = FALSE
)

# Filtrado de datos:
bd_tr <- bd_train %>% filter(row_number() %in% inTrain)       # Conjunto de entrenamiento
bd_validation  <- bd_train %>% filter(!row_number() %in% inTrain)  # Conjunto de validación
```


```{r}
# --- BALANCEO DE CLASES ---
set.seed(1004)  # Misma semilla para consistencia

# downSample: Reduce el desbalanceo de clases mediante submuestreo
# - x: Datos predictores
# - y: Variable objetivo
# - yname: Conserva el nombre original de la variable objetivo
bd_tree1 <- downSample(x = bd_tr,
                      y = bd_tr$Pobre,
                      yname = "Pobre")
```


```{r}
# --- CONFIGURACIÓN DEL MODELO RANDOM FOREST ---
set.seed(1004)  # Reproducibilidad

# Parámetros de control:
# - method = "oob": Usa Out-of-Bag error para validación
fitControl <- trainControl(method = "oob")

# Grid de hiperparámetros:
# - mtry: 30 variables por división
# - splitrule: "gini" (impureza de Gini)
# - min.node.size: Tamaño mínimo de nodo = 13
tree_grid <- expand.grid(
    mtry = 30,
    splitrule = "gini",
    min.node.size = 13
)

# Entrenamiento del modelo:
# - method = "ranger": Implementación eficiente de RF
# - num.trees = 1000: Número de árboles
# - importance = "impurity": Calcula importancia de variables
tree_model1 <- train(
    model_tree1,        # Fórmula definida previamente
    data = bd_tree1,    # Datos balanceados
    method = "ranger",  
    trControl = fitControl,
    tuneGrid = tree_grid,
    num.trees = 1000,
    importance = "impurity"
)
```

```{r}
# --- EVALUACIÓN DEL MODELO ---
# Predicciones en el conjunto de validación
predictions <- predict(tree_model1, bd_validation)

# Creación de dataframe con:
# - id: Identificador
# - Pobre: Valor real
# - Pobre_hat: Predicción del modelo
df_pred <- bd_validation %>%
  select(id, Pobre) %>%
  mutate(Pobre_hat = predictions)

# Cálculo de métrica F1-Score:
# - Evalúa el balance entre precisión y recall
# - positive = "1": La clase positiva es "1" (Pobre)
F1_Score(y_pred = df_pred$Pobre_hat, y_true = df_pred$Pobre, positive = "1")
```
