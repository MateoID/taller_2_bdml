---
title: "script_taller2"
output: null
date: "2025-03-19"
editor_options: 
  markdown: 
    wrap: 72
---

Cargando librerias

```{r}
require(pacman)

p_load(
  tidyverse,
  caret,
  glmnet,
  Metrics,
  MLmetrics,
  skimr,
  xgboost,
  biglm,
  data.table
  )
```

Cargando los datos

```{r}
#Cargamos bases de datos 
raw_data_path <- '../data'
predictions_path <- '../results/predictions'

# Datos 
bd_train <- read.csv(file.path(raw_data_path, 'bd_train_limpia.csv'))
bd_test <- read.csv(file.path(raw_data_path, 'bd_test_limpia.csv'))

```

Haciendo ajustes sobre la variable predicha

```{r}
# Ajustando los niveles de la variable Pobre
bd_train <- bd_train %>% mutate(Pobre=factor(Pobre,levels=c(1,0),labels=c("pobre","No_pobre")))

# Verificando la estructura de la variable predicha. 
str(bd_train$Pobre)  
prop.table(table(bd_train$Pobre))
```

# Regresión logística

## GLM - binomial

### Función métricas F1

creando una función personalizada que use el F1 score para elegir el
mejor modelo.

```{r function_metrics}

sixStats <- function(data, lev = NULL, model = NULL) {
  # Calcula las métricas estándar
  twoClass <- twoClassSummary(data, lev, model)
  default <- defaultSummary(data, lev, model)
  
  # Calcula el F1 Score
  f1 <- F1_Score(data$obs, data$pred, positive = lev[1])
  
  # Combina todas las métricas
  c(twoClass, default, F1 = f1)
}


```

### Ajustando el train control

```{r}
# Control de entrenamiento
ctrl <- trainControl(
  method = "cv",
  number = 10,
  summaryFunction = sixStats,
  classProbs = TRUE,      # Necesario para ROC/F1
  savePredictions = TRUE, # Para calcular métricas
  verboseIter = FALSE
)
```

### Entrenando el modelo

```{r}
# Declarando la semilla para reproducibilidad
set.seed(123)  

# Entrenamiento del modelo
modelo <- train(
  Pobre ~ Clase + Dominio + num_room + 
                      num_bed + propiedad + pago_amort + renta_h + 
                      renta_r + Nper + Depto + suma_antiguedad + promedio_antiguedad + 
                      tiene_empleado_publico + tiene_patron + tiene_cuenta_propia + 
                      tiene_emp_domestico + tiene_jornalero + tiene_sin_remuneracion + 
                      n_posiciones_lab_distintas + aux_trans + ind_prima + prima_serv + prima_nav + 
                      prima_vac + ind_viaticos + ocupado + ind_oficio + ind_arriendo + pet_trabajo + 
                      max_educ + hr_extr + otro_tr + rem_ext + reg_cotiz + cotiz_pen + ing_otros + 
                      edad_prom + perc_fem,   
  data = bd_train,
  method = "glm",
  family = binomial(),
  trControl = ctrl,
  metric = "F1",       # Optimizar por F1
  maximize = TRUE,     # Queremos maximizar F1
  preProcess = c("center", "scale")
)

# Resultados
print(modelo$results)
```

Algunos otros aspectos del modelo:

```{r}
# Mostrar todas las métricas almacenadas en el modelo
print(modelo$resample)
```

### Exportando predicciones

Ahora preparamos el archivo de output para subir la predicción de
pobreza a Kaggle usando la base de test.

```{r}
# Obtener predicciones (clases: "No_Pobre" o "Pobre")
predicciones_clase <- predict(modelo, newdata = bd_test)

# Convertir a 0 y 1 (para el formato de Kaggle)
predicciones_numericas <- ifelse(predicciones_clase == "No_pobre", 0, 1)

#Crear CSV para Kaggle
submission <- data.frame(
  id = bd_test$id,
  pobre = predicciones_numericas
)

# Create descriptive filename
filename <- sprintf("%s/LR-GLM_10fold_F1optimized_%s.csv", 
                   predictions_path,
                   format(Sys.time(), "%Y%m%d_%H%M"))

# 6. Save with proper format
write.csv(submission, 
          file = filename,
          row.names = FALSE,
          quote = FALSE)

```

## Linear Discriminant Analysis (LDA)

### Configurando el train control:

```{r}
# Control de entrenamiento
ctrl_lda <- trainControl(
  method = "cv",
  number = 10,
  summaryFunction = sixStats,
  classProbs = TRUE,      # Necesario para ROC/F1
  savePredictions = TRUE, # Para calcular métricas
  verboseIter = FALSE
)
```

### Entrenando el modelo

```{r}
# Declarando la semilla para reproducibilidad
set.seed(123)  

# Entrenamiento del modelo
modelo_lda <- train(
  Pobre ~ Clase + Dominio + num_room + 
                      num_bed + propiedad + pago_amort + renta_h + 
                      renta_r + Nper + Depto + suma_antiguedad + promedio_antiguedad + 
                      tiene_empleado_publico + tiene_patron + tiene_cuenta_propia + 
                      tiene_emp_domestico + tiene_jornalero + tiene_sin_remuneracion + 
                      n_posiciones_lab_distintas + aux_trans + ind_prima + prima_serv + prima_nav + 
                      prima_vac + ind_viaticos + ocupado + ind_oficio + ind_arriendo + pet_trabajo + 
                      max_educ + hr_extr + otro_tr + rem_ext + reg_cotiz + cotiz_pen + ing_otros + 
                      edad_prom + perc_fem,   
  data = bd_train,
  method = "lda",
  trControl = ctrl_lda,
  metric = "F1",       # Optimizar por F1
  maximize = TRUE,     # Queremos maximizar F1
  preProcess = c("center", "scale")
)

# Resultados
print(modelo_lda$results)
```

```{r}
modelo_lda$resample
```

### Exportando predicciones

Ahora preparamos el archivo de output para subir la predicción de
pobreza a Kaggle usando la base de test.

```{r}
# Obtener predicciones (clases: "No_Pobre" o "Pobre")
predicciones_clase <- predict(modelo_lda, newdata = bd_test)

# Convertir a 0 y 1 (para el formato de Kaggle)
predicciones_numericas <- ifelse(predicciones_clase == "No_pobre", 0, 1)

#Crear CSV para Kaggle
submission <- data.frame(
  id = bd_test$id,
  pobre = predicciones_numericas
)

# Create descriptive filename
filename <- sprintf("%s/LR-LDA_10fold_withF1_%s.csv", 
                   predictions_path,
                   format(Sys.time(), "%Y%m%d_%H%M"))

# 6. Save with proper format
write.csv(submission, 
          file = filename,
          row.names = FALSE,
          quote = FALSE)
```

##Quadratic Discriminant Analysis (QLD)

### Configurando el train control

```{r}
sixStats <- function(data, lev = NULL, model = NULL) {
  # Calcula las métricas estándar
  twoClass <- twoClassSummary(data, lev, model)
  default <- defaultSummary(data, lev, model)
  
  # Calcula el F1 Score
  f1 <- F1_Score(data$obs, data$pred, positive = lev[1])
  
  # Combina todas las métricas
  c(twoClass, default, F1 = f1)
}

# 1. Preprocesamiento mejorado
preProc <- c("center", "scale", "nzv", "corr")

# 2. Control de entrenamiento revisado
ctrl_qda <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = sixStats,
  classProbs = TRUE,
  savePredictions = "final",
  verboseIter = FALSE,
  allowParallel = TRUE
)

```

### Entrenando el modelo


```{r}
# asegurando reproducibilidad
set.seed(123)

# Primero verificamos las variables
nzv <- nearZeroVar(bd_train, saveMetrics = TRUE)
print(nzv[nzv$nzv, ])  # Ver qué variables podrían causar problemas

# Seleccionamos solo variables informativas
predictors <- names(bd_train)[!names(bd_train) %in% c("Pobre", "id")]  # Ajustar según tu dataset
predictors <- predictors[!predictors %in% rownames(nzv[nzv$nzv, ])]
predictors <- predictors[predictors != "Ingtotug"]


# Filtrar bd_test para que solo tenga las variables necesarias para la predicción
bd_test_filtered <- bd_test[, c("id", predictors)] 

# Fórmula con variables seleccionadas
formula_qda <- as.formula(paste("Pobre ~", paste(predictors, collapse = " + ")))

# Entrenamiento final
modelo_qda <- train(
  formula_qda,
  data = bd_train,
  method = "qda",
  trControl = ctrl_qda,
  metric = "F1",
  maximize = TRUE,
  preProcess = preProc
)

# Resultados
print(modelo_qda$results)
```

```{r}
modelo_qda$resample
```
### Exportando predicciones

```{r}

# Obtener predicciones del modelo QDA
predicciones_clase <- predict(modelo_qda, newdata = bd_test_filtered)

# Convertir a 0 y 1 (para el formato de Kaggle)
predicciones_numericas <- ifelse(predicciones_clase == "No_pobre", 0, 1)

#Crear CSV para Kaggle
submission <- data.frame(
  id = bd_test$id,
  pobre = predicciones_numericas
)

# Create descriptive filename
filename <- sprintf("%s/LR-QDA_10fold_withF1_%s.csv", 
                   predictions_path,
                   format(Sys.time(), "%Y%m%d_%H%M"))

# 6. Save with proper format
write.csv(submission, 
          file = filename,
          row.names = FALSE,
          quote = FALSE)
```

## K-nearest neighbors (KNN)

### Configurando el train control
```{r}
sixStats <- function(data, lev = NULL, model = NULL) {
  # Calcula las métricas estándar
  twoClass <- twoClassSummary(data, lev, model)
  default <- defaultSummary(data, lev, model)
  
  # Calcula el F1 Score
  f1 <- F1_Score(data$obs, data$pred, positive = lev[1])
  
  # Combina todas las métricas
  c(twoClass, default, F1 = f1)
}

# 1. Control de entrenamiento 
ctrl_knn <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = sixStats,
  classProbs = TRUE,
  savePredictions = "final",
  verboseIter = FALSE,
  allowParallel = TRUE
)
```


### Entrenando el modelo

```{r}
# # asegurando reproducibilidad
# set.seed(123)
# 
# # ES MUY PESADO
# 
# # Entrenamiento del modelo
# modelo_knn <- train(
#   Pobre ~ Clase + Dominio + num_room +
#                       num_bed + propiedad + pago_amort + renta_h +
#                       renta_r + Nper + Depto + suma_antiguedad + promedio_antiguedad +
#                       tiene_empleado_publico + tiene_patron + tiene_cuenta_propia +
#                       tiene_emp_domestico + tiene_jornalero + tiene_sin_remuneracion +
#                       n_posiciones_lab_distintas + aux_trans + ind_prima + prima_serv + prima_nav +
#                       prima_vac + ind_viaticos + ocupado + ind_oficio + ind_arriendo + pet_trabajo +
#                       max_educ + hr_extr + otro_tr + rem_ext + reg_cotiz + cotiz_pen + ing_otros +
#                       edad_prom + perc_fem,
#   data = bd_train,
#   method = "knn",
#   tuneGrid = expand.grid(k = seq(5, 30, by = 2)),  # Rango más equilibrado
#   trControl = ctrl_knn,
#   metric = "F1",
#   maximize = TRUE,
#   preProcess = c("center", "scale")
# )
# 
# # Resultados
# print(modelo_knn)
```

### Exportando predicciones

```{r}

# # Obtener predicciones del modelo QDA
# predicciones_clase <- predict(modelo_knn, newdata = bd_test)
# 
# # Convertir a 0 y 1 (para el formato de Kaggle)
# predicciones_numericas <- ifelse(predicciones_clase == "No_pobre", 0, 1)
# 
# #Crear CSV para Kaggle
# submission <- data.frame(
#   id = bd_test$id,
#   pobre = predicciones_numericas
# )
# 
# # Create descriptive filename
# filename <- sprintf("%s/LR-knn_5fold_withF1_%s.csv",
#                    predictions_path,
#                    format(Sys.time(), "%Y%m%d_%H%M"))
# 
# # 6. Save with proper format
# write.csv(submission,
#           file = filename,
#           row.names = FALSE,
#           quote = FALSE)
```

##Balanceo con PSM y GLM-binomial(mejor LR)

### Haciendo el balanceo con PSM 
```{r}
library(MatchIt)

# Convertir la variable objetivo a binaria (1 = Pobre, 0 = No pobre)
bd_train <- bd_train %>%
  mutate(Pobre_binario = ifelse(Pobre == "Pobre", 1, 0))

# Aplicar PSM (1:1 matching sin reemplazo, método "nearest neighbor")
psm_model <- matchit(
  Pobre ~ Clase + Dominio + num_room + 
                      num_bed + propiedad + pago_amort + renta_h + 
                      renta_r + Nper + Depto + suma_antiguedad + promedio_antiguedad + 
                      tiene_empleado_publico + tiene_patron + tiene_cuenta_propia + 
                      tiene_emp_domestico + tiene_jornalero + tiene_sin_remuneracion + 
                      n_posiciones_lab_distintas + aux_trans + ind_prima + prima_serv + prima_nav + 
                      prima_vac + ind_viaticos + ocupado + ind_oficio + ind_arriendo + pet_trabajo + 
                      max_educ + hr_extr + otro_tr + rem_ext + reg_cotiz + cotiz_pen + ing_otros + 
                      edad_prom + perc_fem,  
  data = bd_train,
  method = "nearest",
  distance = "glm",  # Propensity score con regresión logística
  ratio = 1,        # 1 no-pobre por cada pobre
  replace = FALSE   # Sin reemplazo
)

# Extraer la muestra balanceada
bd_train_balanced <- match.data(psm_model)

# revisando el balanceo
summary(psm_model)  # Deberías ver mejora en el balance (ej: menor "Std. Mean Diff.")
table(bd_train_balanced$Pobre)  # Ahora ~50% pobres y 50% no pobres

```

### Función métricas F1

creando una función personalizada que use el F1 score para elegir el
mejor modelo.

```{r function_metrics}

sixStats <- function(data, lev = NULL, model = NULL) {
  # Calcula las métricas estándar
  twoClass <- twoClassSummary(data, lev, model)
  default <- defaultSummary(data, lev, model)
  
  # Calcula el F1 Score
  f1 <- F1_Score(data$obs, data$pred, positive = lev[1])
  
  # Combina todas las métricas
  c(twoClass, default, F1 = f1)
}


```

### Ajustando el train control

```{r}
# Control de entrenamiento
ctrl <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = sixStats,
  classProbs = TRUE,      # Necesario para ROC/F1
  savePredictions = TRUE, # Para calcular métricas
  verboseIter = FALSE
)
```

### Entrenando el modelo

```{r}
# Declarando la semilla para reproducibilidad
set.seed(123)  

# Entrenamiento del modelo
modelo_bal_glm <- train(
  Pobre ~ Clase + Dominio + num_room + 
                      num_bed + propiedad + pago_amort + renta_h + 
                      renta_r + Nper + Depto + suma_antiguedad + promedio_antiguedad + 
                      tiene_empleado_publico + tiene_patron + tiene_cuenta_propia + 
                      tiene_emp_domestico + tiene_jornalero + tiene_sin_remuneracion + 
                      n_posiciones_lab_distintas + aux_trans + ind_prima + prima_serv + prima_nav + 
                      prima_vac + ind_viaticos + ocupado + ind_oficio + ind_arriendo + pet_trabajo + 
                      max_educ + hr_extr + otro_tr + rem_ext + reg_cotiz + cotiz_pen + ing_otros + 
                      edad_prom + perc_fem,   
  data = bd_train,
  method = "glm",
  family = binomial(),
  trControl = ctrl,
  metric = "F1",       # Optimizar por F1
  maximize = TRUE,     # Queremos maximizar F1
  preProcess = c("center", "scale")
)

# Resultados
print(modelo_bal_glm$results)
```

Algunos otros aspectos del modelo:

```{r}
# Mostrar todas las métricas almacenadas en el modelo
print(modelo_bal_glm$resample)
```


### Exportando predicciones

Ahora preparamos el archivo de output para subir la predicción de
pobreza a Kaggle usando la base de test.

```{r}
# Obtener predicciones (clases: "No_Pobre" o "Pobre")
predicciones_clase <- predict(modelo_bal_glm, newdata = bd_test)

# Convertir a 0 y 1 (para el formato de Kaggle)
predicciones_numericas <- ifelse(predicciones_clase == "No_pobre", 0, 1)

#Crear CSV para Kaggle
submission <- data.frame(
  id = bd_test$id,
  pobre = predicciones_numericas
)

# Create descriptive filename
filename <- sprintf("%s/LR-GM_bal_5fold_%s.csv", 
                   predictions_path,
                   format(Sys.time(), "%Y%m%d_%H%M"))

# 6. Save with proper format
write.csv(submission, 
          file = filename,
          row.names = FALSE,
          quote = FALSE)

```

## GLM con EN

### Función métricas F1

creando una función personalizada que use el F1 score para elegir el
mejor modelo.

```{r function_metrics}

sixStats <- function(data, lev = NULL, model = NULL) {
  # Calcula las métricas estándar
  twoClass <- twoClassSummary(data, lev, model)
  default <- defaultSummary(data, lev, model)
  
  # Calcula el F1 Score
  f1 <- F1_Score(data$obs, data$pred, positive = lev[1])
  
  # Combina todas las métricas
  c(twoClass, default, F1 = f1)
}


```

### Ajustando el train control

```{r}
# Control de entrenamiento
ctrl <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = sixStats,
  classProbs = TRUE,      # Necesario para ROC/F1
  savePredictions = TRUE, # Para calcular métricas
  verboseIter = FALSE
)
```

### Entrenando el modelo

```{r}
# Declarando la semilla para reproducibilidad
set.seed(123)  

# Entrenamiento del modelo
modelo_glm_en <- train(
  Pobre ~ Clase + Dominio + num_room + 
                      num_bed + propiedad + pago_amort + renta_h + 
                      renta_r + Nper + Depto + suma_antiguedad + promedio_antiguedad + 
                      tiene_empleado_publico + tiene_patron + tiene_cuenta_propia + 
                      tiene_emp_domestico + tiene_jornalero + tiene_sin_remuneracion + 
                      n_posiciones_lab_distintas + aux_trans + ind_prima + prima_serv + prima_nav + 
                      prima_vac + ind_viaticos + ocupado + ind_oficio + ind_arriendo + pet_trabajo + 
                      max_educ + hr_extr + otro_tr + rem_ext + reg_cotiz + cotiz_pen + ing_otros + 
                      edad_prom + perc_fem,   
  data = bd_train,
  method = "glmnet",
  family = "binomial",
  trControl = ctrl,
  preProcess = c("center", "scale"),
  metric = "F1",       # Optimizar por F1
  maximize = TRUE,     # Queremos maximizar F1
  tuneGrid=expand.grid(
  alpha = seq(0, 1, by = 0.1),  # Valores intermedios entre Ridge y Lasso
  lambda = 10^seq(-4, 0, length = 20)  # Desde 0.0001 hasta 1
    )
)

# Resultados
print(modelo_glm_en)
ggplot(modelo_glm_en)  # Gráfico de tuning
```

```{r}
print(modelo_glm_en$results)
```


Algunos otros aspectos del modelo:

```{r}
# Mostrar todas las métricas almacenadas en el modelo
print(modelo_glm_en$resample)
```

### Exportando predicciones

Ahora preparamos el archivo de output para subir la predicción de
pobreza a Kaggle usando la base de test.

```{r}
# Obtener predicciones (clases: "No_Pobre" o "Pobre")
predicciones_clase <- predict(modelo_glm_en, newdata = bd_test)

# Convertir a 0 y 1 (para el formato de Kaggle)
predicciones_numericas <- ifelse(predicciones_clase == "No_pobre", 0, 1)

#Crear CSV para Kaggle
submission <- data.frame(
  id = bd_test$id,
  pobre = predicciones_numericas
)

# Create descriptive filename
filename <- sprintf("%s/LR-GLMNET_5fold_F1optimized_%s.csv", 
                   predictions_path,
                   format(Sys.time(), "%Y%m%d_%H%M"))

# 6. Save with proper format
write.csv(submission, 
          file = filename,
          row.names = FALSE,
          quote = FALSE)

```




