---
title: "script_taller2"
output: null
date: "2025-03-19"
editor_options: 
  markdown: 
    wrap: 72
---

Cargando librerias

```{r}
require(pacman)

p_load(tidyverse, # tidy-data
       rpart, # Recursive Partition and Regression Trees (To run Trees)
       caret ,  # for model training and tunning
       rpart.plot, ## for trees graphs
       Metrics, ## Evaluation Metrics for ML
       MLmetrics, # Evaluation Metrics for ML
       ipred,  # For Bagging 
       ranger #For random Forest
       themis, # For oversampling
       )   
```

Cargando los datos

```{r}
#Cargamos bases de datos 
raw_data_path <- '../data'
predictions_path <- '../results/predictions'

# Datos 
bd_train <- read.csv(file.path(raw_data_path, 'bd_train_limpia.csv'))
bd_test <- read.csv(file.path(raw_data_path, 'bd_test_limpia.csv'))

```

Haciendo ajustes sobre la variable predicha

```{r}
# Ajustando los niveles de la variable Pobre
bd_train <- bd_train %>% mutate(Pobre=factor(Pobre,levels=c(1,0),labels=c("pobre","No_pobre")))

# Verificando la estructura de la variable predicha. 
str(bd_train$Pobre)  
prop.table(table(bd_train$Pobre))
```

# CARTs

## Modelo básico

creando una función personalizada que use el F1 score para elegir el
mejor modelo.

### Configuración del control

```{r function_metrics}

sixStats <- function(data, lev = NULL, model = NULL) {
  # Calcula las métricas estándar
  twoClass <- twoClassSummary(data, lev, model)
  default <- defaultSummary(data, lev, model)
  
  # Calcula el F1 Score
  f1 <- F1_Score(data$obs, data$pred, positive = lev[1])
  
  # Combina todas las métricas
  c(twoClass, default, F1 = f1)
}


```


```{r}
# Control de entrenamiento
ctrl_c1 <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = sixStats,
  classProbs = TRUE,      # Necesario para ROC/F1
  savePredictions = TRUE, # Para calcular métricas
  verboseIter = FALSE
)

# especificamos la grilla de los alphas
grid <- expand.grid(cp = seq(0, 0.04, by = 0.01))
```

### Entrenando el modelo

```{r}
# Declarando la semilla para reproducibilidad
set.seed(123)  

# Entrenamiento del modelo
cv_tree_1 <- train(
    Pobre ~ Cabecera + Dominio + num_room + 
                      num_bed + propiedad + pago_amort + renta_h + 
                      renta_r + Nper + Depto + suma_antiguedad + promedio_antiguedad + 
                      tiene_empleado_publico + tiene_patron + tiene_cuenta_propia + 
                      tiene_emp_domestico + tiene_jornalero + tiene_sin_remuneracion+ 
                      n_posiciones_lab_distintas + aux_trans + ind_prima + prima_serv + prima_nav +
                      prima_vac + ind_viaticos + ind_oficio + ind_arriendo + pet_trabajo +
                      max_educ:ocupado + hr_extr + otro_tr + rem_ext + reg_cotiz + cotiz_pen + ing_otros +
                      edad_prom + perc_fem,
               data = bd_train,
               method = "rpart", 
               trControl = ctrl_c1, 
               tuneGrid = grid, 
               metric= "F1" 
               )
cv_tree_1

```

### Exportando predicciones

Ahora preparamos el archivo de output para subir la predicción de
pobreza a Kaggle usando la base de test.

```{r}
# Obtener predicciones (clases: "No_Pobre" o "Pobre")
predicciones_clase <- predict(cv_tree_1, newdata = bd_test)

# Convertir a 0 y 1 (para el formato de Kaggle)
predicciones_numericas <- ifelse(predicciones_clase == "No_pobre", 0, 1)

#Crear CSV para Kaggle
submission <- data.frame(
  id = bd_test$id,
  pobre = predicciones_numericas
)

# Create descriptive filename
filename <- sprintf("%s/CART-cp0_5fold_F1optimized_%s.csv", 
                   predictions_path,
                   format(Sys.time(), "%Y%m%d_%H%M"))

# 6. Save with proper format
write.csv(submission, 
          file = filename,
          row.names = FALSE,
          quote = FALSE)

```



## Modelo con variables seleccionadas

### Configuración del control

```{r}
# Control de entrenamiento
ctrl_c2 <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = sixStats,
  classProbs = TRUE,      # Necesario para ROC/F1
  savePredictions = TRUE, # Para calcular métricas
  verboseIter = FALSE
)

# especificamos la grilla de los alphas
grid_2 <- expand.grid(cp = seq(0, 0.0115, by = 0.002))
```

### Entrenando el modelo

```{r}
# Declarando la semilla para reproducibilidad
set.seed(123)  

# Entrenamiento del modelo
cv_tree_2 <- train(
    Pobre ~ max_educ:ocupado + num_room + Nper +tiene_empleado_publico + tiene_patron + tiene_cuenta_propia +
      ind_prima + prima_serv + prima_nav + prima_vac + ind_viaticos + ocupado + cotiz_pen + edad_prom,
               data = bd_train,
               method = "rpart", 
               trControl = ctrl_c2, 
               tuneGrid = grid_2, 
               metric= "F1" 
               )
cv_tree_2

```
### Exportando predicciones

Ahora preparamos el archivo de output para subir la predicción de
pobreza a Kaggle usando la base de test.

```{r}
# Obtener predicciones (clases: "No_Pobre" o "Pobre")
predicciones_clase <- predict(cv_tree_2, newdata = bd_test)

# Convertir a 0 y 1 (para el formato de Kaggle)
predicciones_numericas <- ifelse(predicciones_clase == "No_pobre", 0, 1)

#Crear CSV para Kaggle
submission <- data.frame(
  id = bd_test$id,
  pobre = predicciones_numericas
)

# Create descriptive filename
filename <- sprintf("%s/CART-cp0_5fold_F1op_somevar_%s.csv", 
                   predictions_path,
                   format(Sys.time(), "%Y%m%d_%H%M"))

# 6. Save with proper format
write.csv(submission, 
          file = filename,
          row.names = FALSE,
          quote = FALSE)

```


## Modelo usando oversampling up

### Configuración del control
```{r}

# Control de entrenamiento
ctrl_c3 <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = sixStats,
  classProbs = TRUE,      # Necesario para ROC/F1
  savePredictions = TRUE, # Para calcular métricas
  verboseIter = FALSE, 
  sampling = "up",  # Upsampling de la clase "pobre" (oversampling)
)

# especificamos la grilla de los alphas
grid_cart_c3 <- expand.grid(cp = seq(0, 0.0001, by = 0.00001))

```

### Entrenando el modelo
```{r}
cv_tree_c3 <- train(
      Pobre ~ Cabecera + Dominio + num_room + 
                      num_bed + propiedad + pago_amort + renta_h + 
                      renta_r + Nper + Depto + suma_antiguedad + promedio_antiguedad + 
                      tiene_empleado_publico + tiene_patron + tiene_cuenta_propia + 
                      tiene_emp_domestico + tiene_jornalero + tiene_sin_remuneracion+ 
                      n_posiciones_lab_distintas + aux_trans + ind_prima + prima_serv + prima_nav +
                      prima_vac + ind_viaticos + ocupado + ind_oficio + ind_arriendo + pet_trabajo +
                      max_educ + edad_prom + hr_extr + otro_tr + rem_ext + reg_cotiz + cotiz_pen + ing_otros +
                      perc_fem,  # Usa todas las variables (o ajusta la fórmula)
  data = bd_train,
  method = "rpart",
  trControl = ctrl_c3,
  tuneGrid = grid_cart_c3,
  metric = "F1" 
)

cv_tree_c3
```

### Exportando predicciones

```{r}
# Obtener predicciones (clases: "No_Pobre" o "Pobre")
predicciones_clase <- predict(cv_tree_c3, newdata = bd_test)

# Convertir a 0 y 1 (para el formato de Kaggle)
predicciones_numericas <- ifelse(predicciones_clase == "No_pobre", 0, 1)

#Crear CSV para Kaggle
submission <- data.frame(
  id = bd_test$id,
  pobre = predicciones_numericas
)

# Create descriptive filename
filename <- sprintf("%s/CART-cp0_5fold_F1op_upsampl_%s.csv", 
                   predictions_path,
                   format(Sys.time(), "%Y%m%d_%H%M"))

# 6. Save with proper format
write.csv(submission, 
          file = filename,
          row.names = FALSE,
          quote = FALSE)
```


## Modelo usando SMOTE

### Configuración del control
```{r}

# Control de entrenamiento
ctrl_c4 <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = sixStats,
  classProbs = TRUE,      # Necesario para ROC/F1
  savePredictions = TRUE, # Para calcular métricas
  verboseIter = FALSE, 
  sampling = "smote",  
)

# especificamos la grilla de los alphas
grid_cart_c4 <- expand.grid(cp = seq(0, 0.0002, by = 0.00002))

```

### Entrenando el modelo
```{r}
cv_tree_c4 <- train(
      Pobre ~ Cabecera + Dominio + num_room + 
                      num_bed + propiedad + pago_amort + renta_h + 
                      renta_r + Nper + Depto + suma_antiguedad + promedio_antiguedad + 
                      tiene_empleado_publico + tiene_patron + tiene_cuenta_propia + 
                      tiene_emp_domestico + tiene_jornalero + tiene_sin_remuneracion+ 
                      n_posiciones_lab_distintas + aux_trans + ind_prima + prima_serv + prima_nav +
                      prima_vac + ind_viaticos + ocupado + ind_oficio + ind_arriendo + pet_trabajo +
                      max_educ + edad_prom + hr_extr + otro_tr + rem_ext + reg_cotiz + cotiz_pen + ing_otros +
                      perc_fem,  # Usa todas las variables (o ajusta la fórmula)
  data = bd_train,
  method = "rpart",
  trControl = ctrl_c4,
  tuneGrid = grid_cart_c4,
  metric = "F1" 
)

cv_tree_c4
```


### Exportando predicciones

```{r}
# Obtener predicciones (clases: "No_Pobre" o "Pobre")
predicciones_clase <- predict(cv_tree_c4, newdata = bd_test)

# Convertir a 0 y 1 (para el formato de Kaggle)
predicciones_numericas <- ifelse(predicciones_clase == "No_pobre", 0, 1)

#Crear CSV para Kaggle
submission <- data.frame(
  id = bd_test$id,
  pobre = predicciones_numericas
)

# Create descriptive filename
filename <- sprintf("%s/CART-cp0_5fold_F1op_SMOTE_%s.csv", 
                   predictions_path,
                   format(Sys.time(), "%Y%m%d_%H%M"))

# 6. Save with proper format
write.csv(submission, 
          file = filename,
          row.names = FALSE,
          quote = FALSE)
```









## Modelo usando oversampling up

### Configuración del control
```{r}

# Control de entrenamiento
ctrl_c3 <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = sixStats,
  classProbs = TRUE,      # Necesario para ROC/F1
  savePredictions = TRUE, # Para calcular métricas
  verboseIter = FALSE, 
  sampling = "up",  # Upsampling de la clase "pobre" (oversampling)
)

# especificamos la grilla de los alphas
grid_cart_c3 <- expand.grid(cp = seq(0.0003, 0.0005, by = 0.000001))

```

### Entrenando el modelo
```{r}
cv_tree_c3 <- train(
      Pobre ~ Cabecera + Dominio + num_room + 
                      num_bed + propiedad + pago_amort + renta_h + 
                      renta_r + Nper + Depto + suma_antiguedad + promedio_antiguedad + 
                      tiene_empleado_publico + tiene_patron + tiene_cuenta_propia + 
                      tiene_emp_domestico + tiene_jornalero + tiene_sin_remuneracion+ 
                      n_posiciones_lab_distintas + aux_trans + ind_prima + prima_serv + prima_nav +
                      prima_vac + ind_viaticos + ocupado + ind_oficio + ind_arriendo + pet_trabajo +
                      max_educ + edad_prom + hr_extr + otro_tr + rem_ext + reg_cotiz + cotiz_pen + ing_otros +
                      perc_fem,  # Usa todas las variables (o ajusta la fórmula)
  data = bd_train,
  method = "rpart",
  trControl = ctrl_c3,
  tuneGrid = grid_cart_c3,
  metric = "F1" 
)

cv_tree_c3
```


